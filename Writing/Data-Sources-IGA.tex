\documentclass[
      12pt,
        ]{article}






% --- type and typeface? -----------------------
\usepackage{lmodern}

% input
\usepackage[utf8]{inputenc}
\usepackage{upquote}
% typography
\usepackage{microtype}


\usepackage[T1]{fontenc}


% text block
\usepackage{setspace}
\usepackage[              left = 1in,top = 1in,right = 1in,bottom = 1in             ]{geometry}

\usepackage{enumitem}
  \setlist{noitemsep}



% decimal numbering for appendix figs and tabs


% Deletes section counters
% \setcounter{secnumdepth}{0}









  \usepackage{natbib}
  \bibliographystyle{agsm.bst}
  % protect underscores in most circumstances
  % \usepackage[strings]{underscore} 

    % to allow underscores in labels (e.g. citesO 

\usepackage[english]{babel}


% 

% \newtheorem{hypothesis}{Hypothesis}

\makeatletter
  \@ifpackageloaded{hyperref}{}{%
    \ifxetex
      % page size defined by xetex
      % unicode breaks when used with xetex
      \PassOptionsToPackage{hyphens}{url}\usepackage[setpagesize = false, 
                                                     unicode = false, 
                                                     xetex]{hyperref}
    \else
      \PassOptionsToPackage{hyphens}{url}\usepackage[unicode = true]{hyperref}
    \fi
  }

  \@ifpackageloaded{color}{
    \PassOptionsToPackage{usenames,dvipsnames}{color}
  }{
    \usepackage[usenames,dvipsnames]{color}
  }
\makeatother

\hypersetup{breaklinks = true,
            bookmarks = true,
            pdfauthor = {Daniel Carpenter (Harvard University) and Devin Judge-Lord (University of Wisconsin) and Brian Libgober (Yale University) and Steven Rashin (New York University)},
             pdfkeywords  =  {Interest groups, rulemaking, lobbying, bureaucratic politics, data
sources},  
            pdftitle = {Data and Methods for Analyzing Special Interest Influence in Rulemaking},
            colorlinks = true,
            citecolor = blue,
            urlcolor = blue,
            linkcolor = magenta,
            pdfborder = {0 0 0}}

\urlstyle{same}  % don't use monospace font for urls


% set default figure placement to htbp
\makeatletter
  \def\fps@figure{hbtp}
\makeatother


% optional footnotes as endnotes
  \usepackage{endnotes}
  \renewcommand{\enotesize}{\normalsize}
  \let\footnote = \endnote


% ----- Pandoc wants this tightlist command ----------
\providecommand{\tightlist}{
  \setlength{\itemsep}{0pt}
  \setlength{\parskip}{0pt}
}





% --- title & section styles -----------------------


% title, author, date
  \title{Data and Methods for Analyzing Special Interest Influence in Rulemaking}

  \author{ % author, option footnote, optional affiliation
            Daniel Carpenter  \\ \emph{Harvard University} 
             \and 
           % author, option footnote, optional affiliation
            Devin Judge-Lord  \\ \emph{University of Wisconsin} 
             \and 
           % author, option footnote, optional affiliation
            Brian Libgober  \\ \emph{Yale University} 
             \and 
           % author, option footnote, optional affiliation
            Steven Rashin\footnote{Corresponding Author:
\href{mailto:Steven.Rashin@NYU.edu}{\nolinkurl{Steven.Rashin@NYU.edu}},
19 West 4th St, 2nd Floor, New York, NY 10012}  \\ \emph{New York University} 
            }

% auto-format date?
  \date{\today}


% abstract
\usepackage{abstract}
  \renewcommand{\abstractname}{}    % clear the title
  \renewcommand{\absnamepos}{empty} % originally center

 % \newcommand*{\authorfont}{\sffamily\selectfont}


% section titles
\usepackage[small, bf, sc]{titlesec}
  % \titleformat*{\subsection}{\itshape}
  \titleformat*{\subsubsection}{\itshape} 
  \titleformat*{\paragraph}{\itshape} 
  \titleformat*{\subparagraph}{\itshape}




\usepackage{floatrow}
\floatsetup[figure]{capposition=top}
\floatsetup[table]{capposition=top}
\usepackage{multirow}
\usepackage{rotating} 
\usepackage{caption}




\begin{document}
 

% --- PAGE: title and abstract -----------------------

  \maketitle

  \pagenumbering{gobble}



  \begin{abstract}
    \noindent The United States government creates astonishingly complete records of
policy creation in executive agencies. In this article, we describe the
major kinds of data that have proven useful to scholars studying
interest group behavior and influence in bureaucratic politics, how to
obtain them, and challenges that we as users have encountered in working
with these data. We discuss established databases such as
regulations.gov, which contains comments on draft agency rules, and
newer sources of data, such as ex-parte meeting logs, which describe the
interest groups and individual lobbyists that bureaucrats are meeting
face-to-face about proposed policies. One challenge is that much of
these data are not machine-readable. We argue that scholars should
invest in several projects to make these datasets machine-readable and
to link them to each other as well as to other databases. 

          \hfill \\ 
      \noindent \emph{Keywords}: Interest groups, rulemaking, lobbying, bureaucratic politics, data
sources 
    
  \end{abstract}



% --- PAGE: contents -----------------------




% --- PAGE: body -----------------------


  \newpage
  \pagenumbering{arabic}

\noindent 
      \doublespacing 
    \noindent Submission ID: IGAD-D-19-00044

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

If the U.S. federal government is unquestionably good at one thing, it
is pushing out paper. In theory, governmental records relevant to the
creation of policy via agency rulemaking have long been available to
researchers. Given its volume and quasi-legislative nature, rulemaking
is generally required to be more transparent than more individualized
decision-making such as adjudication, enforcement, awarding grants, or
making contracts. In practice, however, obtaining information on what is
happening during rulemaking has been costly and challenging. In the
1990s and early 2000s, leading research was limited to data on just a
few rules \citep[e.g.,][]{GoldenJPART1998} or surveys
\citep[e.g.,][]{FurlongJPART2004}. Since 1994, when the government first
released the \emph{Federal Register} online, data on notice-and-comment
rulemaking have become increasingly detailed and now include data on
draft policies, the activities of policymakers, and interest group
advocacy \citep[see][ for a recent review]{Yackee2019}.

In this article, we describe data sources that have proven useful to
scholars studying interest group lobbying of federal agencies, how to
obtain them, and also challenges in working with these data. Some of
these data sources we discuss are machine-readable records of all agency
rules published in the \emph{Federal Register}, comments posted on
regulations.gov, metadata about rules contained in the Unified Agenda,
and Office of Management and Budget (OMB) reports. We also describe
sources that have become more available in recent years, such as
ex-parte meeting logs and individually-identified personnel records of
nearly all federal employees since 1973. For background theory on
lobbying and interest group influence over agency policymaking, see
\citet{Carpenter2013}.

These data sources do not exhaust the kinds of records relevant to
researchers. They reflect what is available at present, but new data
sources emerge constantly. Thus, we also highlight datasets that may
soon become more accessible or available, perhaps after enterprising
researchers submit the necessary Freedom Of Information Act (FOIA)
requests. Examples include agency press releases \citep[see,
e.g.,][]{LibgoberQJPS, Libgober2018} and the Foreign Agents Registration
Act (FARA) reports \citep{ShepherdAPSR2019}.\footnote{We link to more
  relevant data sources on our GitHub page:
  \url{https://github.com/libgober/regdata/blob/master/README.md.}} To
orient potential students of agency policymaking to available sources of
data, we identify four units of analysis: (1) participants, (2)
policymakers, (3) policy texts, and (4) metadata (e.g., policy timing).
We describe where to find data on each in roughly the order that they
appear in the process of developing a rule.

\hypertarget{background-rulemaking-and-the-administrative-procedures-act}{%
\subsection{Background: Rulemaking and the Administrative Procedures
Act}\label{background-rulemaking-and-the-administrative-procedures-act}}

For decades, the volume of legal requirements emerging from executive
agencies has dwarfed the lawmaking activity of Congress. Each year,
agencies publish three thousand or more regulations. In doing so,
agencies must generally follow a process prescribed by the
Administrative Procedures Act (APA), 5 U.S.C. ยง 553(c). For each rule,
agencies create a collection of documents at each stage of their
policymaking process. Section 553 requires agencies to issue a Notice of
Proposed Rulemaking (NPRM) in the \emph{Federal Register} to notify
potentially affected parties that the regulatory environment or program
administration may change. Following the NPRM, agencies post these
proposed rules and comments from interested stakeholders and individuals
on their websites or regulations.gov. Agencies are required to consider
public comments but are not required to alter rules based on them. These
documents are organized in a `docket' folder with a unique name and ID
number. Once kept in literal folders in each agency's `docket room',
where visitors could make photocopies, these documents are now online.
For example, the Centers for Medicare \& Medicaid Services rulemaking
docket on health plans disclosing costs can be accessed at
\url{regulations.gov/docket?D=CMS-2019-0163}. The fact that the APA
requires agencies to assemble a comprehensive record of who sought to
influence the policymaking process -- and that such records are
relatively complete -- is unusual for federal policymaking. This makes
agency policymaking particularly exciting for interest group scholars.

\hypertarget{who-participates-in-the-rulemaking-process}{%
\section{Who participates in the rulemaking
process?}\label{who-participates-in-the-rulemaking-process}}

Public attention in rulemaking is remarkably skewed. A few rules, such
as the Federal Communication Commission's rules on net neutrality,
receive millions of comments. In contrast, half of the proposed rules
open for comment on regulations.gov received no comments at all
\citep{LibgoberJOP}. Such dramatic variation in public participation
challenges the idea of a ``typical'' rule or rulemaking participant.
Participants include businesses, public interest groups, trade
associations, unions, law firms, and academics
\citep{CuellarALR2005, YackeeJOP2006}. While businesses are the most
consistent and influential participants in most rulemakings
\citep{YackeeJOP2006, LibgoberJOP}, most comments come from public
pressure campaigns targeting a relatively small number of rules; at
least 39 million of the 48 million comments on proposed rules on
regulations.gov were mobilized by just 100 advocacy organizations such
as the Sierra Club \citep{judgelord2019SPSA}.

Because interest groups seek to influence rules, scholars are interested
in patterns of participation in rulemaking. For example,
\citet{YouJOP2017} finds that half of all spending on lobbying
legislation occurs \emph{after} a bill becomes law. Participation in
this process can begin even before a proposed rule is issued.
\citet{deFigureidoKimICC2004} show that meetings between agency
officials and firms spike before an agency issues a policy.
\citet{LibgoberQJPS} finds that firms that meet with federal regulators
before a rule is issued may receive abnormally high stock market returns
upon its release. Leveraging high-frequency trading data, Libgober shows
that in the minutes and hours following the publication of proposed
rules at the Federal Reserve, the firms that met with the Board during
rule-development significantly outperformed matched market competitors
that did not obtain such early access. These findings are consistent
with the analysis of qualitative researchers that commenters who
participate early in the rulemaking process can shape the content of the
rule \citep{NaughtonJPAM2009}.

Scholars are also interested in how participation in rulemaking may
affect a rule's ultimate fate when it is sent to the White House Office
of Management and Budget (OMB) or in judicial review. Interest groups
can secure policy concessions by lobbying during OMB review
\citep{HaederAPSR2015}. They also use the rulemaking record to build a
case for litigation. Yet, there are few large-N studies linking lobbying
in rulemaking to litigation or court decisions.
\citet{LibgoberRashin2018SPSA} analyzed comments submitted to financial
regulators and found that threats of litigation were rare, and even
comments that seemed to ``threaten'' litigation rarely culminated in a
judicial decision. Yet, most court decisions involving challenges to
rules did follow comments that threatened litigation.
\citet{judgelord2016MPSA} found no relationship between the number of
comments and the likelihood that the Supreme Court upheld or struck down
an agency rule.

To analyze patterns of participation, scholars use data from a variety
of sources. Sources for data on participation are agency rulemaking
dockets
\citep{GoldenJPART1998, YackeeJPART2006, YoungBP2017, BanBP2019}, the
\emph{Federal Register} \citep{BallaAPSR1998, WestPAR2004}, and
regulations.gov \citep{BallaPI2019, GordonRashinJOP}. Though commenters
are not generally required to disclose their names and affiliations,
many do. The best current data sources for obtaining the names of the
organizations that submit comments on federal regulations are
regulations.gov and the websites of the independent agencies themselves.

\hypertarget{obtaining-and-working-with-data-on-comment-participants}{%
\subsection{Obtaining and working with data on comment
participants}\label{obtaining-and-working-with-data-on-comment-participants}}

Scholars wishing to obtain data on comments and commenters from
executive agencies generally use the website
\href{regulations.gov}{regulations.gov}. Obtaining these data requires
overcoming several technical and bureaucratic hurdles. First, retrieving
bulk data from regulations.gov requires the use of an Application
Programming Interface (API).\footnote{An API is a set of procedures that
  allow a user to access data from a website in a structured way. Some
  websites, like regulations.gov, limit API usage by requiring users to
  get an API key, see
  \url{https://regulationsgov.github.io/developers/}.} Second, getting
an accurate count of comments is not straightforward as agencies have
different policies regarding duplicated comments\footnote{The difference
  between the number of reported comments and the number of comments on
  regulations.gov is often because some agencies group mass-comment
  campaigns into a single document. A small number of comments on
  regulations.gov are duplicates posted in error. To resolve a
  discrepancy, we recommend searching the agency's website or contacting
  the agency directly.} and confidential business information
\citep{Lubbers2012}.

Third, downloading these data can be time-consuming. As of February 29,
2020, Regulations.gov has 12,227,522 public submission documents
representing over 70 million public comments, over 80 thousand rules,
and nearly 1.5 million other documents. Regulations.gov is subject to a
rate limit of 1,000 queries per hour, making it difficult for scholars
seeking to analyze rules with tens of thousands of comments. This limit
is particularly problematic for rules where the majority of comments are
attachments, as downloading an individual document requires calling the
API twice (once for the docket information, which includes the
attachment URL(s), and then a second time to download the linked file).
Fourth, not all federal agencies post rulemaking documents to
regulations.gov. For these agencies, scholars studying participation in
rulemaking can often obtain data from the agency's website.\footnote{For
  example, the Federal Energy Regulatory Commission has posted all
  comments they receive on their eLibrary website, but not all of these
  appear on regulations.gov. Unlike regulations.gov, most agency sites
  do not have an API and thus require bespoke web scrapers. We offer
  examples of scrapers for regulations.gov and several of these agencies
  on \url{https://github.com/libgober/regdata}.}

\indent After obtaining comment data, scholars must choose how they want
to preprocess the names of the organizations that comment. This step is
vital as organizations such as Goldman Sachs and the American Bar
Association, for example, submit comments using multiple versions of
their names. These decisions can have a substantial impact on the
analysis as misidentifying organizations may result in them being
dropped or double-counted. Fuzzy matching, using an algorithm to
identify the similarity (or ``distance'') between two strings of text,
can help but is not a panacea. For example, the algorithm will show a
small distance between Goldman Sachs and Goldman Sachs \& Co but can
show similarly small distances between distinct entities and it cannot
separate multiple organizations with the same acronym (e.g., the
American Bankers' Association and American Bar Association both comment
as the ABA).

\hypertarget{who-writes-rules}{%
\section{Who writes rules?}\label{who-writes-rules}}

Political scientists have long used personal identity and social
networks to understand political outcomes. In the last decade, the
emergence of new data sources made it easier to learn about rulewriters'
identities and networks. Some of the most important data sources in this
regard are the U.S. Office of Personnel Management's (OPM) data on
government employees \citep[e.g.,][]{BoltonAMP2018},\footnote{Note that
  the dataset \citet{BoltonAMP2018} used is not public.} Open Secrets'
lobbying \citep[e.g.,][]{Baumgartner2009} and revolving door databases
\citep[e.g.,][]{VidalAER2012, BertrandAER2014}, machine-readable
lobbying disclosure act reports
\citep[e.g.,][]{BoehmkeJPP2013, YouJOP2017, Dwidar2019SPSA}, meeting
logs \citep{LibgoberQJPS}, and datasets of corporate board membership
such as Boardex \citep[e.g.,][]{ShiveROF2016}. \citet{CarriganPAR2019}
illustrate the possibilities of these new data sources. They find that
the number of job functions of the bureaucrats who write the rules is
associated with both decreases in the time an agency takes to promulgate
a rule and increases in the probability that the rule will be struck
down in court. In an innovative study of unionization,
\citet{ChenJTP2015} link OPM data to Adam Bonica's DIME ideology scores
to classify the ideology of agency staff over time. These early efforts
suggest that there are exciting opportunities to study who writes the
rules and how it matters.

\hypertarget{obtaining-and-working-with-personnel-and-lobbying-data}{%
\subsection{Obtaining and working with personnel and lobbying
data}\label{obtaining-and-working-with-personnel-and-lobbying-data}}

Scholars can obtain data on agency personnel from the BuzzFeed personnel
data release, which contains information such as employee salaries, job
titles, and demographic data from 1973 through 2016.\footnote{Available
  at
  \url{https://archive.org/details/opm-federal-employment-data/page/n1}.
  Updated personnel files are available through 2018 from the OPM itself
  here: \url{https://www.fedscope.opm.gov/datadefn/index.asp}} These are
the most comprehensive personnel records publicly accessible, but they
have limitations. First, not all agencies and occupations are a part of
this release.\footnote{These data exclude at least 16 agencies and,
  within the covered agencies, law enforcement officers, nuclear
  engineers, and certain investigators \citet{Singer-Vine2017}.} Second,
some of the employees in these data do not have unique identification
numbers, and common names such as `John Smith' match multiple employees.
For example, the Veterans Health Administration employed 24 John Smiths
in 2014, five with the same middle initial.

To obtain machine-readable data on the identities of domestic lobbyists,
scholars use two databases from Open Secrets -- a nonprofit that tracks
spending on politics -- on administrative and Congressional lobbying.
Downloading the lobbying data is straightforward; it only requires an
account to access the `bulk data' page. The lobbying data comes from the
required disclosures under the Lobbying Disclosure Act of 1995 (LDA).
Note that the reporting threshold varies by type of firm (in-house have
a higher minimum reporting threshold than lobbying firms) and over
time.\footnote{See
  \url{https://lobbyingdisclosure.house.gov/ldaguidance.pdf} for
  details.} The lobbying data covers 1999 through 2018 and is broken up
into seven machine-readable tables.\footnote{These data are here:
  \url{https://www.opensecrets.org/bulk-data/download?f=Lobby.zip}} We
prefer the Open Secrets data to the raw Senate data as the Open Secrets
version contains more machine-readable information. Lobbying data is
subject to several limitations; the reports do not contain exact
monetary amounts and some lobbyists do not disclose required
contacts.\footnote{See \url{https://www.gao.gov/assets/700/698103.pdf}}
Open Secrets also has a database on revolving door employees that shows
the career paths of federal government workers that went to private
sector work that depends on interacting with the federal
government.\footnote{See
  \url{https://www.opensecrets.org/revolving/methodology.php}. Unlike
  their lobbying database, this dataset has no bulk data option and must
  be scraped.}

Lobbyists advocating for foreign clients are required to disclose these
contacts under the Foreign Agent Registration Act. Foreign agents often
lobby bureaucratic agencies; Israel, for example, retained law firm
Arnold \& Porter for advice on registering securities with the
Securities and Exchange Commission (SEC).\footnote{See
  \url{https://efile.fara.gov/docs/1750-Supplemental-Statement-20110729-13.pdf}}
In addition to the participants, the reports also contain the nature of
the contact and the specific officials contacted. These data are
astonishingly complete -- the website contains all 6264 FARA registrants
and their foreign contacts since 1942.\footnote{See
  \url{https://efile.fara.gov/ords/f?p=1381:1:13132679194789:::::}} The
FARA data is \emph{not} all in machine-readable form.\footnote{Only the
  metadata (e.g., names) are machine-readable.} Consequently, scholars
using these data only focus on a subset such as \citet{You2019} who
focuses on lobbying activities by Colombia, Panama, and South Korea. We
caution users that the same participant may appear under multiple names.

Corporate executives, lawyers, and lobbyists often have contacts with
agency officials, called \emph{ex parte} communications
\citep{Lubbers2012}, to discuss rules outside of the public comment
process. While record-keeping practices for these meetings vary
considerably, they are often publicly available on agency websites.
Because meetings data are held in different places on each agency's
website, obtaining these data requires writing a web scraper for each
agency. As there are no uniform standards for reporting meeting data,
these data differ substantially from agency to agency in both content
and organization. The Federal Reserve, for example, groups meetings by
subject, not by rule,\footnote{\url{https://www.federalreserve.gov/regreform/communications-with-public.htm}}
the SEC groups meetings by rule, and the Commodity Futures Trading
Commission (CFTC) and Federal Communication Commission (FCC) meeting
records are not grouped at all.\footnote{See
  \url{https://www.cftc.gov/LawRegulation/DoddFrankAct/ExternalMeetings?page=6}
  and
  \url{https://www.fcc.gov/proceedings-actions/ex-parte/archive-of-filings}}
Meeting participants are typically individually identified, but some
agencies only report the names of the organization represented, and
others report meeting topics but not participants. We suspect that
missingness varies by agency, but are not aware of any study evaluating
missingness in meeting record disclosures.

\hypertarget{what-do-the-rules-say}{%
\section{What do the rules say?}\label{what-do-the-rules-say}}

The literature on rulemaking in political science and public
administration has focused on whether public participation influences
the content of rules
\citep[e.g.,][]{BallaAPSR1998, CuellarALR2005, YackeeJOP2006, NaughtonJPAM2009, Wagner_ALR_2011, HaederAPSR2015, HaederJPART2018, GordonRashinJOP, Rashin2019}.
Knowing what the rules say and how these texts have changed from
proposal to finalization is crucial studying commenter influence. Rule
preambles, which describe what the agency has tried to accomplish and
how it has engaged with stakeholders, are especially useful. The legally
operative text is often less useful to social scientists because
interpreting legal text usually requires substantial domain expertise.
However, where interpretation is straightforward, such as rate-setting,
scholars can capture variation in legally operative texts
\citep{BallaAPSR1998, GordonRashinJOP}.

\hypertarget{obtaining-and-working-with-data-on-rule-text}{%
\subsection{Obtaining and Working with Data on Rule
Text}\label{obtaining-and-working-with-data-on-rule-text}}

The federal government publishes all rules in the \emph{Federal
Register}, accessible via FederalRegister.gov. This database is
comprehensive and has machine-readable records of all regulations
published after 1994 and optical versions from 1939-1993.\footnote{See
  \url{https://www.govinfo.gov/app/collection/fr/}} The \emph{Federal
Register} API does not have any rate limits. The Federal Register office
assigns every regulatory action a document number. In our experience,
this `FR Doc Number' is the only truly unique and consistently
maintained identifier for proposed and final rules.

While the raw text of rules is relatively straightforward to obtain,
there are several thorny theoretical and methodological issues that
scholars must overcome.\footnote{However, because rules are usually
  published as PDFs, converting them to raw text for analysis introduces
  errors.} First, the standard path from NPRM to public comments to
final rule is not always straightforward. Some rules are withdrawn
before a final rule. Other agencies issue interim final rules subject
change. For studies that seek to compare the proposed and final rules,
the most problematic rules are the ones where one proposed rule gets
broken up into a few smaller final rules or the reverse, where short
rules become bundled into one final rule. These rules pose challenges
for inference as the processes that lead to amalgamation or separation
are not well understood. Second, scholars must determine how to
preprocess the rulemaking data before feeding these data to a text
analysis algorithm.

\hypertarget{obtaining-and-working-with-rule-metadata}{%
\section{Obtaining and working with rule
metadata}\label{obtaining-and-working-with-rule-metadata}}

Rulemaking metadata, such as the time rules are released, allow scholars
to answer questions about factors that affect the rulemaking
environment. Scholars use this data to study questions about regulatory
delay
\citep[e.g.,][]{ACSPSQ2013, ThrowerPSQ2018, PotterJOP2017, CarriganPAR2019, CarpenterAJPS2011},
agenda-setting \citep[e.g.,][]{CoglianeseALR2016}, and the financial
impact of rules \citep[e.g.,][]{LibgoberQJPS}. These scholars relied on
data from the Office of Information and Regulatory Affairs (OIRA)
\citep{ACSPSQ2013, CarriganPAR2019}, the Unified Agenda
\citep{CoglianeseALR2016, PotterJOP2017}, the \emph{Federal Register}
\citep{ThrowerPSQ2018}, press releases \citep{Libgober2018}, and the
Food and Drug Administration's drug approval and postmarket experience
database \citep{CarpenterAJPS2011}.

Obtaining data from the Unified Agenda is relatively straightforward as
all of these documents since 1995 are available online in
machine-readable form.\footnote{The Unified Agenda from 1983 through
  1994 is available in the \emph{Federal Register}.} The Unified Agenda
contains many of the proposed regulations that agencies plan to issue in
the near future, making it an extremely useful data source for studying
questions about agenda setting and timing \citep[e.g.,][]{Potter2019}.
There are, however, significant limitations to these data. First,
agencies report early-stage rulemaking to the Unified Agenda
strategically \citep{NouSCLR2016}. Second, agencies do not list all
`failed' rules that did not become final rules in the Unified Agenda
\citep{YackeeGWLR2012}. Third, \citet{CoglianeseALR2016} note that the
Unified Agenda misses much of the regulatory agency's work, including
enforcement actions, adjudicatory actions, and decisions not to act.

As addressed elsewhere in this issue {[}NOTE: reference to OMB article
here{]}, many rules, especially rules that are controversial or deemed
economically significant, are reviewed by OIRA (a subagency of OMB).
Obtaining OIRA data is relatively straightforward, as all of these
documents since 1981 are available online in machine-readable form.
These data include the date on which OIRA received the draft rule from
the agency, whether the review was expedited, and whether the rule is
determined to be `economically significant' or affect `federalism'.

In addition to disclosures mandated by law, agencies often issue press
releases for agency actions. Much like the meetings data discussed
above, policies regarding the storage and dissemination of press
releases differ from agency to agency. The Federal Reserve's website,
for example, lists all press releases since 1996, while the SEC only has
them since 2012.\footnote{See
  \url{https://www.federalreserve.gov/newsevents/pressreleases.htm} and
  \url{https://www.sec.gov/news/pressreleases}} When working with press
releases, scholars often need data on the exact time documents were made
available to the general public \citep[see, e.g.,][]{LibgoberJOP}. Press
release metadata, such as the exact time a press release becomes public,
can often be extracted from Really Simple Syndication (RSS) feeds.

Each data source has different types of missingness and different
limitations regarding the information it contains about each rule. For
example, data from OIRA only contains rules reviewed by OMB. The Unified
Agenda covers a broader scope of policies, but due to strategic
reporting and frequent reporting errors, desired cases may be missing.
For published draft and final rules, these missing cases may be found in
a more reliable source like the \emph{Federal Register}, OIRA reports,
or regulations.gov. The \emph{Federal Register} is the most reliable
source for rule texts but contains the least amount of rule metadata and
only includes \emph{published} draft and final rules. Some rulemaking
projects that did not reach the published draft (NPRM) stage may be
missing from all datasets. More importantly, the diversity of these data
sources means that, for a given query, one source will often include
cases that a second does not, while the second source includes variables
that first does not.

\hypertarget{discussion-assembling-complete-databases}{%
\section{Discussion: Assembling Complete
Databases}\label{discussion-assembling-complete-databases}}

The United States government releases troves of data on rulemaking. Yet,
these data require substantial effort from scholars to be useful for
research. Scholars working on bureaucratic politics face two primary
data tasks: (1) assembling complete, machine-readable datasets of agency
rulemaking activity and (2) linking observations across datasets. In the
near term, we see four major projects to make data more accessible,
prevent duplicated efforts to download and clean data, and thus increase
the efficiency of research efforts. First, a complete database is needed
to link commenting activity throughout the Federal government.
Researchers should be able to query and download these data in bulk,
including comment text and metadata. Second, a comprehensive database
could link observations of the revolving door for rulewriters and
participants across OPM personnel records, LDA disclosure forms, and
FARA data. This database could be augmented with data from networking
sites like LinkedIn. Third, a database could link all meeting activities
throughout the federal government. Finally, unique identifiers for each
commenter and organization would allow researchers to link commenting
behavior across datasets and to other information about these
organizations. These projects would allow scholars to pursue novel
research on political participation, influence, and public management.

\hypertarget{conflicts-of-interest}{%
\section{Conflicts of Interest}\label{conflicts-of-interest}}

On behalf of all authors, the corresponding author states that there is
no conflict of interest.
% --- PAGE: endnotes -----------------------
  \newpage 
  \theendnotes
% --- PAGE: refs -----------------------
\newpage
\singlespacing 
          \bibliography{dataig.bib} 
  \end{document}