\documentclass[
      12pt,
        ]{article}






% --- type and typeface? -----------------------
\usepackage{lmodern}

% input
\usepackage[utf8]{inputenc}
\usepackage{upquote}
% typography
\usepackage{microtype}


\usepackage[T1]{fontenc}


% text block
\usepackage{setspace}
\usepackage[              left = 1in,top = 1in,right = 1in,bottom = 1in             ]{geometry}

\usepackage{enumitem}
  \setlist{noitemsep}



% decimal numbering for appendix figs and tabs


% Deletes section counters
% \setcounter{secnumdepth}{0}









  \usepackage{natbib}
  \bibliographystyle{apsr2}
  % protect underscores in most circumstances
  % \usepackage[strings]{underscore} 

    % to allow underscores in labels (e.g. citesO 

\usepackage[english]{babel}


% 

% \newtheorem{hypothesis}{Hypothesis}

\makeatletter
  \@ifpackageloaded{hyperref}{}{%
    \ifxetex
      % page size defined by xetex
      % unicode breaks when used with xetex
      \PassOptionsToPackage{hyphens}{url}\usepackage[setpagesize = false, 
                                                     unicode = false, 
                                                     xetex]{hyperref}
    \else
      \PassOptionsToPackage{hyphens}{url}\usepackage[unicode = true]{hyperref}
    \fi
  }

  \@ifpackageloaded{color}{
    \PassOptionsToPackage{usenames,dvipsnames}{color}
  }{
    \usepackage[usenames,dvipsnames]{color}
  }
\makeatother

\hypersetup{breaklinks = true,
            bookmarks = true,
            pdfauthor = {Daniel Carpenter (Harvard University) and Devin Judge-Lord (University of Wisconsin) and Brian Libgober (Yale University) and Steven Rashin (New York University)},
             pdfkeywords  =  {Interest groups, rulemaking, lobbying, bureaucratic politics, data
sources},  
            pdftitle = {Data and Methods for Analyzing Special Interest Influence in Rulemaking},
            colorlinks = true,
            citecolor = blue,
            urlcolor = blue,
            linkcolor = magenta,
            pdfborder = {0 0 0}}

\urlstyle{same}  % don't use monospace font for urls


% set default figure placement to htbp
\makeatletter
  \def\fps@figure{hbtp}
\makeatother


% optional footnotes as endnotes


% ----- Pandoc wants this tightlist command ----------
\providecommand{\tightlist}{
  \setlength{\itemsep}{0pt}
  \setlength{\parskip}{0pt}
}





% --- title & section styles -----------------------


% title, author, date
  \title{Data and Methods for Analyzing Special Interest Influence in Rulemaking}

  \author{ % author, option footnote, optional affiliation
            Daniel Carpenter  \\ \emph{Harvard University} 
             \and 
           % author, option footnote, optional affiliation
            Devin Judge-Lord  \\ \emph{University of Wisconsin} 
             \and 
           % author, option footnote, optional affiliation
            Brian Libgober  \\ \emph{Yale University} 
             \and 
           % author, option footnote, optional affiliation
            Steven Rashin\footnote{Corresponding Author:
\href{mailto:Steven.Rashin@NYU.edu}{\nolinkurl{Steven.Rashin@NYU.edu}},
19 West 4th St, 2nd Floor, New York, NY 10012}  \\ \emph{New York University} 
            }

% auto-format date?
  \date{\today}


% abstract
\usepackage{abstract}
  \renewcommand{\abstractname}{}    % clear the title
  \renewcommand{\absnamepos}{empty} % originally center

 % \newcommand*{\authorfont}{\sffamily\selectfont}


% section titles
\usepackage[small, bf, sc]{titlesec}
  % \titleformat*{\subsection}{\itshape}
  \titleformat*{\subsubsection}{\itshape} 
  \titleformat*{\paragraph}{\itshape} 
  \titleformat*{\subparagraph}{\itshape}




\usepackage{floatrow}
\floatsetup[figure]{capposition=top}
\floatsetup[table]{capposition=top}
\usepackage{multirow}
\usepackage{rotating} 
\usepackage{caption}




\begin{document}
 

% --- PAGE: title and abstract -----------------------

  \maketitle

  \pagenumbering{gobble}



  \begin{abstract}
    \noindent The United States government creates astonishingly complete records
relevant to policy creation in executive agencies. In this article, we
describe the major kinds of data that have proven useful to scholars
studying interest group behavior in bureaucratic politics, how to obtain
them, and challenges that we as users have encountered in working with
these data. We discuss databases such as regulations.gov, which contains
comments on draft rules proposed by executive branch agencies, and new
sources of data, such as ex-parte meeting logs, which describe the
interest groups and individual lobbyists that bureaucrats are meeting
face-to-face about proposed policies. One challenge is that some of
these data are not machine-readable. We argue that a productive way
forward is to invest in making all the datasets machine-readable and to
create a consistent way to link them to each other as well as to outside
databases. 

          \hfill \\ 
      \noindent \emph{Keywords}: Interest groups, rulemaking, lobbying, bureaucratic politics, data
sources 
    
  \end{abstract}



% --- PAGE: contents -----------------------




% --- PAGE: body -----------------------


  \newpage
  \pagenumbering{arabic}

\noindent 
      \doublespacing 
    \noindent Submission ID: IGAD-D-19-00044

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

If the U.S. federal government is unquestionably good at one thing, it
is pushing out paper. In theory, governmental records relevant to the
creation of policy in executive agencies have long been available to
researchers. Practically speaking, obtaining such data has been a costly
and challenging undertaking. A decade or more ago, researchers were
limited to acquiring data on just a few rules
\citep[e.g.,][]{GoldenJPART1998} or using surveys
\citep[e.g.,][]{FurlongJPART2004}. Since 1994, when the government first
released the \emph{Federal Register} online, scholars have had access to
astonishingly detailed data on the notice-and-comment rulemaking process
and, hence, regulatory policy, regulatory policymakers, and interest
group advocacy.

In this article, we describe the kinds of data that have proven useful
to scholars studying interest group behavior in federal agencies, how to
obtain them, and also challenges that we have found in working with
these data. Three examples of data sources that fit this description are
machine-readable records of all agency rules published since 1994,
comments available on regulations.gov, and metadata about rules
contained in the Unified Agenda. We also describe sources that have
become more available in recent years, such as ex-parte meeting
logs\footnote{These logs record who participated in face-to-face or
  telephone meetings between interest groups and bureaucrats, often
  including individual names.} and individually-identified personnel
records of nearly all federal employees since 1973
\citep{Singer-Vine2017}.

These data sources do not exhaust the kinds of records relevant to
researchers. They reflect what is available at present, but new data
sources emerge constantly. Thus, we also highlight sources of data that
we believe are already or may soon become available, perhaps after
enterprising researchers submit the necessary Freedom Of Information Act
(FOIA) requests. Examples include agency press releases \citep[see,
e.g.,][\citet{Libgober2018}]{LibgoberJOP} and the Foreign Agents
Registration Act (FARA) reports \citep{ShepherdAPSR2019}.\footnote{We
  link to all the relevant data sources on our GitHub page:
  \url{https://github.com/libgober/regdata/blob/master/README.md}.} To
orient potential students of agency policymaking to available sources of
data, we identify four units of analysis: (1) participants, (2)
policymakers, (3) policy texts, and (4) metadata such as policy timing.
We describe where to find data on each in roughly the order they appear
in the process of developing a rule.

\hypertarget{background-rulemaking-and-the-administrative-procedures-act}{%
\subsection{Background: Rulemaking and the Administrative Procedures
Act}\label{background-rulemaking-and-the-administrative-procedures-act}}

For decades, the volume of legal requirements emerging from executive
agencies has dwarfed the lawmaking activity of Congress, the Supreme
Court, and the Presidency. Each year agencies publish four thousand or
more regulations. In doing so, agencies are generally required to follow
a process prescribed in Section 553 of the Administrative Procedures Act
(APA). For each rule, agencies create a collection of documents that
mark the stages of this policymaking process. Section 553 requires an
agency to issue a Notice of Proposed Rulemaking (NPRM) in the
\emph{Federal Register} to notify potentially affected parties that the
regulatory environment might change. Following the NPRM, agencies
solicit comments on these regulations through regulations.gov (for
executive agencies) or the agency websites themselves (for independent
agencies). Agencies are required to consider the comments but are not
required to alter the rules based on them. These documents are organized
in a ``docket'' folder with a unique name and ID number. Once kept in a
literal folder, these documents are now online. For example, the Centers
for Medicare Medicaid Services rulemaking docket 0163 ``Transparency in
Coverage'' can be found at regulations.gov/docket?D=CMS-2019-0163. The
fact that the APA requires agencies to assemble a comprehensive record
of who sought influence over any part of the policy-making process, and
that such records are relatively complete, is highly unusual in the
American federal system and makes the area particularly exciting for
interest group scholars.

\hypertarget{who-participates-in-the-rulemaking-process}{%
\section{Who participates in the rulemaking
process?}\label{who-participates-in-the-rulemaking-process}}

Notice and comment rulemaking creates a unique feature in American
democracy; the right for anyone to participate in, perhaps even
influence, most policymaking processes at federal agencies.
Participation in rulemaking activities is highly skewed. A few rules,
such as the Federal Communication Commission's rules on net neutrality,
receive millions of comments. In contrast, half of proposed rules open
for comment on regulations.gov receive no comments at all
\citep{LibgoberJOP}. Even the median rule designated as ``economically
significant'' -- rules projected to have an annual economic impact of
over \$100 million -- receives fewer than ten comments
\citep{judgelord2019SPSA}. Participants include businesses, public
interest groups, trade associations, unions, law firms, and academics
\citep[\citet{YackeeJOP2006}]{CuellarALR2005}. While businesses are the
most consistent and apparently influential participants
\citep[\citet{LibgoberJOP}]{YackeeJOP2006}, most comments are part of
public pressure campaigns. Indeed, at least 39 million of the 48 million
comments on proposed rules on regulations.gov were mobilized by just 100
organizations \citep{judgelord2019SPSA}.

Scholarly interest in patterns of participation in the policymaking
process relies on the notion that the participants in the process seek
to influence the development of the rule. For example,
\citet{YouJOP2017} finds that half of all spending on lobbying
legislation occurs \emph{after} a bill becomes law. Participation in
this process can begin even before a proposed rule is issued. De
\citet{deFigureidoKimICC2004} show that meetings between agency
officials and firms spike before an agency issues a policy order.
\citet{LibgoberQJPS} finds that firms that meet with federal regulators
before a rule is issued may receive abnormally high stock market returns
upon its release. Leveraging high-frequency trading data, Libgober shows
that in the minutes and hours following the publication of proposed
rules at the Federal Reserve, the firms that met with the Board during
rule-development significantly outperformed matched market competitors
who did not obtain such early access. These findings are consistent with
the analysis of qualitative researchers that commenters who participate
early in the rulemaking process can shape the content of the rule
\citep{NaughtonJPAM2009}. In some cases, public participation can even
initiate a rulemaking process via a petition for rulemaking.

Scholars are also interested in how participation in rulemaking may
affect a rule's ultimate fate when sent to the White House Office of
Management and Budget (OMB) or in judicial review. Interest groups lobby
successfully in OMB review \citep{HaederYackee2015} Interest groups also
use the rulemaking record but build a case for litigation. Yet, there
are few large-N studies linking lobbying in rulemaking to litigation or
court decisions. \citet{LibgoberRashin2018SPSA} analyzed comments
submitted to financial regulators and found that threats of litigation
were rare but, when they did occur, were often followed by court
decisions. \citet{judgelord2016MPSA} found no relationship between the
number of comments and the likelihood that the Supreme Court upheld or
struck down an agency rule and, like \citet{SchuckElliott1990}, found
that the court is more likely to strike down policies made through the
notice and comment process.

To analyze patterns of participation, scholars use data from a variety
of sources. Sources for data on participation are agency rulemaking
dockets
\citep[\citet{YackeeJPART2006},\citet{YoungBP2017},\citet{BanBP2019}]{GoldenJPART1998},
the \emph{Federal Register} \citep[\citet{WestPAR2004}]{BallaAPSR1998},
and regulations.gov \citep[\citet{GordonRashinJOP}]{Balla2019}. Though
commenters are not generally required to disclose their names and
affiliations, many do. The best current data sources for obtaining the
names of the organizations that submit comments on federal regulations
are regulations.gov and the websites of the independent agencies
themselves.

\hypertarget{obtaining-and-working-with-data-on-comment-participants}{%
\subsection{Obtaining and working with data on comment
participants}\label{obtaining-and-working-with-data-on-comment-participants}}

Scholars wishing to obtain data on comments and commenters from
executive agencies generally use the website regulations.gov. Actually
obtaining the data requires overcoming a number of technical and
bureaucratic hurdles. First, bulk data from the website can only be
accessed via an Application Programming Interface (API).\footnote{An API
  is a set of procedures that allow a user to access data from a website
  in a structured way. Some websites limit API usage by requiring users
  to get an API key; regulations.gov is one of those websites.} This
requires requesting an API key.\footnote{By emailing
  \href{mailto:regulations@erulemakinghelpdesk.com}{\nolinkurl{regulations@erulemakinghelpdesk.com}}
  with ``your name, email address, organization, and intended use of the
  API.'' See \url{https://regulationsgov.github.io/developers/} for more
  details. Approval of API keys takes several days. We caution
  prospective users of the site that these keys can be deactivated
  without warning or acknowledgment of why they were deactivated.}
Second, obtaining an accurate count of comments is not straightforward
as agencies have different policies regarding duplicated
comments\footnote{The difference between the total number of reported
  comments and the number of comments on regulations.gov is often due to
  mass comment campaigns being grouped together.} and confidential
business information.\footnote{See e.g., \citet{Lubbers2012} and
  \url{https://www.regulations.gov/userNotice}.} Third, obtaining the
data is time-consuming.\footnote{Regulations.gov is subject to a rate
  limit of 1,000 queries per hour which is especially problematic for
  scholars seeking to analyze the full text of comments, many of which
  are included only as attachments. Downloading an individual document
  requires calling the API twice, once for the docket information, which
  includes the attachment URL(s), and then a second time to download the
  linked file.} As of October 4, 2019, Regulations.gov has 11,238,958
public submission documents representing over 70 million public comments
and almost 1.5 million rules and other documents.\\
~\\
Not all federal agencies post rulemaking documents to regulations.gov.
Scholars studying participation in these agencies can often obtain data
on participation in rulemaking from the agency websites.\footnote{Some
  agencies have only some records on regulations.gov. For example, the
  Federal Energy Regulatory Commission has posted proposed rules on
  regulations.gov, but directed comments to be submitted by email and
  then posted them on its eLibrary website. Unlike regulations.gov, most
  agency sites do not have an API and thus require scholars to use
  bespoke web scrapers. We have examples of scrapers for several of
  these agencies on \url{https://github.com/libgober/regdata}. While
  these websites are not rate-limited or gated with API keys, we
  recommend caution with the rate at which scholars solicit information
  from the servers to avoid security protocols that trigger a temporary
  ban.}

In addition to the challenges of obtaining the data, scholars also must
choose how they want to preprocess the data before analyzing it. For
example, to answer questions about the types of organizations that
participate in rulemaking, scholars first need to accurately identify
these organizations so that they can be assigned the correct covariate
data. This process, however, is not trivial as the same firm can be
identified in numerous ways. For example, Goldman Sachs submitted
comments to the Securities and Exchange Commission (SEC) and Federal
Reserve Board (FRB) as The Goldman Sachs Group, Inc, Goldman Sachs
Co.~LLC, Goldman Sachs Bank USA, Goldman, Sachs \& Co., Goldman Sachs
Execution \& Clearing, LP, among other identifiers. All of these
entities need to be accurately matched to Goldman Sachs, including the
Goldman Sachs Execution \& Clearing comment which is on Goldman Sachs
letterhead.\footnote{See
  \url{https://www.sec.gov/comments/s7-03-10/s70310-43.pdf}.} The
problem can be more acute with associations such as the American Bar
Association (ABA) sometimes commenting as itself and other times as
individual sections of the ABA. One way scholars have been able to get
around this problem is to use fuzzy matching. Fuzzy matching is a
process that compares two strings of text and gives a distance between
them. This procedure will assign a small distance between Goldman Sachs
and Goldman, Sachs \& Co.~and a larger distance between Goldman Sachs
and Merrill Lynch. The distances and optimal thresholds depend on the
algorithm used. Fuzzy matching, however, is not a panacea as the same
procedure will also show a small distance between JP Morgan and Morgan
Stanley, which are two separate entities. It will also not reveal
whether an ABA letter is from the American Banker's Association or the
American Bar Association. Many organizations active on similar
rulemaking issues share acronyms or have similar names. In expectation,
however, noise generated from incorrect matching is likely to bias a
scholar against finding any relationships within the data.

\hypertarget{who-writes-rules}{%
\section{Who writes rules?}\label{who-writes-rules}}

Scholars recently began to study how policymakers' identities and
networks affect the policymaking process. This is partially due to the
release of new data sources such as the U.S. Office of Personnel
Management's (OPM) data on government employees
\citep[e.g.,][]{BoltonAMP2018},\footnote{Note that the dataset
  \citet{BoltonAMP2018} used is not public like the similar BuzzFeed
  data we discuss below.} Open Secrets' lobbying
\citep[e.g.,][]{Baumgartner2009} and revolving door databases
\citep[e.g.,][\citet{BertrandAER2014}]{VidalAER2012}, machine-readable
lobbying disclosure act reports \citep[e.g.,][\citet{YouJOP2017},
\citet{Dwidar2019SPSA}]{BoehmkeJPP2013}, meeting logs
\citep{LibgoberQJPS}, and datasets of corporate board membership such as
Boardex \citep[e.g.,][]{ShiveROF2016}. Scholars have also been able to
study the identities of policymakers through the creative use of
longstanding data sources such as the \emph{Federal Register}
\citep[e.g.,][]{CarriganPAR2019}.

Work on the networks between policymakers and private interests has
reshaped our understanding of the policymaking space. By exploiting
meeting logs, \citet{LibgoberQJPS} finds that comments and meetings with
policymakers are associated with abnormal returns in the billions.
\citet{CarriganPAR2019} find that the number of job functions of the
bureaucrats who write the rules is associated with both decreases in the
time an agency takes to promulgate a rule and increases in the
probability that the rule will be overturned in court.
\citet{VidalAER2012} find evidence that, among lobbyists, connections to
politicians are more valuable than issue expertise. In fact, when a
former Senate aide becomes a lobbyist, the Senator's retirement results
in a substantial loss of income for that lobbyist.

\hypertarget{obtaining-and-working-with-personnel-and-lobbying-data}{%
\subsection{Obtaining and Working with personnel and lobbying
data}\label{obtaining-and-working-with-personnel-and-lobbying-data}}

Scholars can obtain data on agency personnel from the BuzzFeed personnel
data release. The BuzzFeed personnel data\footnote{Available at
  \url{https://archive.org/details/opm-federal-employment-data/page/n1}.
  (The complete dataset is over 30GB).} contains information on federal
employees such as their salaries, job titles, and basic demographic data
from 1973 through 2016.\footnote{Updated personnel files are available
  through 2018 from the OPM itself here:
  \url{https://www.fedscope.opm.gov/datadefn/index.asp}}\\
These are the most comprehensive personnel records publicly available,
but they have significant limitations. First, not all agencies and
occupations are a part of this release.\footnote{The list includes at
  least 16 agencies and, within the covered agencies, law enforcement
  officers, nuclear engineers, and certain investigators (Buzzfeed,
  2017). See
  \url{https://www.buzzfeednews.com/article/jsvine/sharing-hundreds-of-millions-of-federal-payroll-records}}\\
Second, some of the employees in these data do not have unique
identification numbers. This means that common names such as ``John
Smith'' match multiple employees; the Veterans Health Administration
(VHA) employed 24 John Smiths in 2014, five with the same middle
initial.

To obtain machine-readable data on the identities of domestic lobbyists,
scholars use two databases from Open Secrets -- a nonprofit focused on
tracking spending on politics in the US -- on administrative and
Congressional lobbying. Downloading the lobbying data is straightforward
as it only requires an account to access the ``bulk data'' page. The
lobbying data comes from the required disclosures under the Lobbying
Disclosure Act of 1995 (LDA). Note that the reporting threshold varies
by type of firm (in-house have a higher minimum reporting threshold than
lobbying firms) and over time.\footnote{See
  \url{https://lobbyingdisclosure.house.gov/ldaguidance.pdf} for
  details.} The lobbying data covers 1999 through 2018 and is broken up
into seven tables that can easily be loaded into R or Python.\footnote{Note
  that the raw data can be downloaded from the Secretary of the Senate's
  Office of Public Records here:
  \url{https://www.senate.gov/legislative/Public_Disclosure/LDA_reports.htm}}
We note, however, that the data is not complete as some lobbyists do not
disclose required contacts and the data does not contain exact monetary
amounts.\footnote{See \url{https://www.gao.gov/assets/700/698103.pdf}}
We recommend Open Secret's database as it is easier to use than the raw
Senate data. Open Secrets also has a database on revolving door
employees that shows the career paths or federal government workers that
went to the private sector and are employed in some capacity where their
work depends on interacting with the federal government.\footnote{See
  \url{https://www.opensecrets.org/revolving/methodology.php} for
  details.} Unlike their lobbying database, this one must be scraped as
there is no option to download it using bulk data.\footnote{Note that
  they promote academic work using their database, so they do not
  actively discourage scraping their database.}

Lobbyists advocating for foreign clients are required to disclose these
contacts under the Foreign Agent Registration Act. Foreign agents often
lobby bureaucratic agencies; for example, the state Israel retained law
firm, Arnold \& Porter, for advice on, among other issues, registering
securities with the SEC.\footnote{See
  \url{https://efile.fara.gov/docs/1750-Supplemental-Statement-20110729-13.pdf}}
The reports contain a multitude of data including the names of foreign
entities, the firms representing them, the nature of the contact, and
the specific officials contacted. The data are astonishingly complete -
the website contains all 6264 FARA registrants and their foreign
contacts since July 3, 1942. The FARA data can be accessed online
through the Department of Justice.\footnote{\url{https://efile.fara.gov/ords/f?p=1381:1:13132679194789}:::::}
Unlike other data discussed in this essay, the FARA data is \emph{not}
all in machine-readable form;\footnote{The metadata - e.g., dates,
  registratrants, clients - are available in machine-readable form
  through the API or bulk data downloads page.} converting from PDF to a
machine-readable format (e.g., .csv) is neither easy nor error-free. As
a result, scholars using the data only focus on a subset such as
\citet{You2019} who focuses on lobbying activities by the governments of
Colombia, Panama, and South Korea on their free trade agreements from
2003 through 2012. In the absence of a completely digitized archive,
scholars can exploit the search functions to search by lobbying
registrant (e.g., lobbying firm Squire Patton Boggs) or foreign
principal (e.g., the government of Afghanistan). Similar to the
discussion of the diversity of names above, the same actor can
participate under different names. For example, the Embassy of the
Islamic Republic of Afghanistan and the Embassy of Afghanistan are
designated as separate entities under FARA.

Corporate executives, lawyers, and lobbyists often meet with agency
officials to discuss rules. Records of these meetings are often recorded
by agency personnel. Obtaining these data requires writing a web scraper
for each agency that holds the meetings data since the data are held in
different places on each website. Since there are no uniform standards
for reporting meeting data, the data differ substantially from agency to
agency in both content and organization. The Federal Reserve, for
example, groups meetings by subject but not by rule,\footnote{\url{https://www.federalreserve.gov/regreform/communications-with-public.htm}}
the SEC groups meetings by rule, and the CFTC and FCC has all their
meetings in one place.\footnote{See
  \url{https://www.cftc.gov/LawRegulation/DoddFrankAct/ExternalMeetings?page=6}
  and
  \url{https://www.fcc.gov/proceedings-actions/ex-parte/archive-of-filings}}

\hypertarget{what-do-the-rules-say}{%
\section{What do the rules say?}\label{what-do-the-rules-say}}

All of the work discussed above relies on the notion that public
participation and the rulewriters influence the content of rules;
numerous studies have found that commenters influence rules \citep[see,
e.g.,][\citet{YackeeJOP2006},\citet{NaughtonJPAM2009},\citet{HaederAPSR2015},\citet{HaederJPART2018}]{CuellarALR2005}
at agencies such as the Department of Labor \citep{YackeeJOP2006}, the
Department of Treasury \citep{CuellarALR2005}, the Environmental
Protection Agency \citep{WagnerALR2011}, the Securities and Exchange
Commission \citep{Rashin2019}, and numerous other agencies. This finding
is consistent across interviews \citep[e.g.,][]{FurlongJPART1998},
qualitative analysis \citep[e.g.,][]{CuellarALR2005}, and quantitative
analysis \citep[e.g.,][]{YackeeJOP2006}. Firms and groups representing
businesses' interests are influential in securing policy concessions
from the rulemaking process
\citep[\citet{YackeeJOP2006},\citet{Carpenter2013}]{YackeeJPART2006},
particularly when they are unopposed. Other scholars have found that
agencies respond to citizens \citep{BallaPI2019} and medical
professionals \citep[\citet{GordonRashinJOP}]{BallaAPSR1998}.

\hypertarget{obtaining-and-working-with-data-on-rule-text}{%
\subsection{Obtaining and Working with Data on Rule
Text}\label{obtaining-and-working-with-data-on-rule-text}}

One of the most basic functions of the bureaucracy is to issue
regulations that set specific, enforceable requirements implementing a
law. The federal government publishes all rules in the \emph{Federal
Register}, accessible via FederalRegister.gov. This database is
comprehensive and has machine-readable records of all regulations
published after 1994.\footnote{For issues from March 1939 through 1993,
  see \url{https://www.govinfo.gov/app/collection/fr/}, although note
  that they might require optical character recognition to make them in
  a readable format.} Scholars can access search for regulations by the
\emph{Federal Register} citation, e.g., 47 FR 3431, \emph{Federal
Register} number, or, more usefully, through their API; unlike other
APIs mentioned in this essay, the \emph{Federal Register} API does not
have any rate limits.\footnote{However we still recommend small delays
  to prevent flooding the server with requests.}

While the raw text of rules is relatively straightforward to obtain,
there are several thorny theoretical and methodological issues scholars
must overcome.\footnote{We note that raw texts of rules are not
  available from regulations.gov or the independent agencies themselves.
  As these rules are often in PDF form, converting them to .txt for
  analysis introduces errors into the text.} First, the standard path
from notice of proposed rulemaking (NPRM) to public comments to a final
rule is not always straightforward. Some rules are withdrawn before a
final rule. Other agencies issue interim final rules subject to
comments. For studies that seek to compare the proposed and final rules,
the most problematic rules are the ones where one proposed rule gets
broken up into a few smaller final rules or the reverse, where small
rules become bundled into one final rule. These rules pose challenges
for inference as the processes that lead to amalgamation or separation
are not well understood. Second, scholars must decide whether, and to
what extent, they should preprocess the rulemaking data before feeding
the data to a text analysis algorithm.

\hypertarget{rule-metadata}{%
\section{Rule metadata}\label{rule-metadata}}

Rulemaking metadata, such as the time rules are released, allow scholars
to answer questions about factors that affect the rulemaking
environment. Scholars have exploited this data to study questions about
regulatory delay, agenda-setting, and the financial impact of rules.
Often lengthy delays between statutory promulgation and the issuance of
regulations are the subject of recent empirical scholarly interest.
Scholars attribute various causes to regulatory delay including auditing
\citep{ACSPSQ2013}; outside contacts \citep{BallaALR2011}; the political
climate \citep[\citet{ThrowerPSQ2018}]{PotterJOP2017}; personnel types
\citep{CarriganPAR2019}; ossification \citep{YackeeGWLR2012}; deadlines
\citep[\citet{CarpenterAJPS2011},\citet{BertelliPAR2019}]{LavertuJPART2012};
staffing levels \citep{BoltonJLEO2015}. These scholars relied on data
from OIRA
\citep[\citet{BallaALR2011},\citet{BoltonJLEO2015},\citet{CarriganPAR2019}]{ACSPSQ2013},
the Unified Agenda
\citep[\citet{PotterJOP2017},\citet{LavertuJPART2012},\citet{Potter2019}]{BertelliPAR2019},
the \emph{Federal Register}
\citep[\citet{ThrowerPSQ2018}]{YackeeGWLR2012}, and FDA's drug approval
and postmarket experience \citep{CarpenterAJPS2011}. Scholars have also
exploited rule metadata to show that publicly-traded banks that submit
comments account for \$7 billion in excess returns \citep{Libgober2018}.

\hypertarget{obtaining-and-working-with-the-unified-agenda-and-press-releases}{%
\subsection{Obtaining and working with the Unified Agenda and Press
releases}\label{obtaining-and-working-with-the-unified-agenda-and-press-releases}}

Obtaining data from the Unified Agenda is relatively straightforward as
all issues since 1995 are available online in machine-readable
form.\footnote{The Unified Agenda from 1983 through 1994 is available in
  the \emph{Federal Register}.}. The Unified Agenda contains all the
proposed regulations an agency plans to issue in the near future, making
it an extremely useful data source for studying questions about agenda
setting and timing (for example, see \citet{Potter2019}). There are,
however, significant limitations to these data. First, agencies report
their early-stage rulemaking to the Unified Agenda strategically
\citep{NouSCLR2016}. Second, agencies do not list ``failed'' rules that
did not become final rules in the Unified Agenda \citep{YackeeGWLR2012}.
Third, \citet{CoglianeseALR2016} note that the Unified Agenda misses
much of the regulatory agency's work, including enforcement actions,
adjudicatory actions, and decisions not to act.

In addition to the disclosures mandated by law, agencies often issue
press releases to notify the public of important agency actions. Much
like the meetings data discussed above, the policies regarding their
storage and dissemination differ from agency to agency. The Federal
Reserve, for example, lists all press releases since 1996 on their
website, while the SEC only has them from 2012.\footnote{See
  \url{https://www.federalreserve.gov/newsevents/pressreleases.htm} and
  \url{https://www.sec.gov/news/pressreleases}} When working with the
press releases scholars often need data on the exact time documents were
made available to the general public \citep[see, e.g.,][]{LibgoberJOP}.
Obtaining the press release metadata requires exploiting Really Simple
Syndication (RSS) feeds to extract the exact time a press release
becomes public.

\hypertarget{discussion-assembling-complete-databases}{%
\section{Discussion: Assembling Complete
Databases}\label{discussion-assembling-complete-databases}}

The United States government releases troves of data on rulemaking but
in forms that require substantial effort from scholars to be useful for
research. Scholars working on bureaucratic politics face two primary
data challenges going forward: assembling complete, machine-readable
datasets of agency rulemaking activity and linking observations across
datasets. We see four fruitful data projects which could increase
researcher efficiency by preventing duplicated efforts to download and
clean data. First, a complete database is needed to link commenting
activity throughout the Federal government that can be downloaded in
bulk, including comment text and metadata. Second, a comprehensive
database could link revolving door rulemakers from the OPM personnel
records, LDA disclosure forms, and FARA data. This database would be
significantly improved by the addition of data from LinkedIn, but those
data are not currently public. Third, creating a database of all meeting
activities throughout the federal government. Finally, unique
identifiers for each commenter would allow researchers to link
commenting behavior to organizations across datasets. These projects,
once completed, will allow scholars to pursue novel research on
political participation, influence, and public management.

\hypertarget{conflicts-of-interest}{%
\section{Conflicts of Interest}\label{conflicts-of-interest}}

On behalf of all authors, the corresponding author states that there is
no conflict of interest.
% --- PAGE: endnotes -----------------------
% --- PAGE: refs -----------------------
\newpage
\singlespacing 
          \bibliography{dataig.bib} 
  \end{document}